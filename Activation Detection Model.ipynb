{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a925e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f09f6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size to set the model input shape (all data samples)\n",
    "size = 5033880"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20861b6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ac71c",
   "metadata": {},
   "source": [
    "Load all training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c11a801",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5033880)\n",
      "(1, 5033880)\n"
     ]
    }
   ],
   "source": [
    "train1 = pd.read_csv(\"./Lubos_data/dataset/channel_1\", sep='\\t')\n",
    "train2 = pd.read_csv(\"./Lubos_data/dataset/channel_2\", sep='\\t')\n",
    "train3 = pd.read_csv(\"./Lubos_data/dataset/channel_3\", sep='\\t')\n",
    "train4 = pd.read_csv(\"./Lubos_data/dataset/channel_4\", sep='\\t')\n",
    "train5 = pd.read_csv(\"./Lubos_data/dataset/channel_5\", sep='\\t')\n",
    "train6 = pd.read_csv(\"./Lubos_data/dataset/channel_6\", sep='\\t')\n",
    "train7 = pd.read_csv(\"./Lubos_data/dataset/channel_7\", sep='\\t')\n",
    "train8 = pd.read_csv(\"./Lubos_data/dataset/channel_8\", sep='\\t')\n",
    "\n",
    "x_train = np.concatenate([\n",
    "    np.asarray(train1['emg1']), \n",
    "    np.asarray(train2['emg2']), \n",
    "    np.asarray(train3['emg3']),\n",
    "    np.asarray(train4['emg4']),\n",
    "    np.asarray(train5['emg5']),\n",
    "    np.asarray(train6['emg6']),\n",
    "    np.asarray(train7['emg7']),\n",
    "    np.asarray(train8['emg8']),\n",
    "]).reshape(-1, size)\n",
    "\n",
    "y_train = np.concatenate([\n",
    "    np.asarray(train1['class']), \n",
    "    np.asarray(train2['class']), \n",
    "    np.asarray(train3['class']),\n",
    "    np.asarray(train4['class']),\n",
    "    np.asarray(train5['class']),\n",
    "    np.asarray(train6['class']),\n",
    "    np.asarray(train7['class']),\n",
    "    np.asarray(train8['class']),\n",
    "]).reshape(-1, size)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e329cb",
   "metadata": {},
   "source": [
    "Load all testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4fa9cefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5033880)\n",
      "(1, 5033880)\n"
     ]
    }
   ],
   "source": [
    "test1 = pd.read_csv(\"./Lubos_data/dataset/channel_16\", sep='\\t')\n",
    "test2 = pd.read_csv(\"./Lubos_data/dataset/channel_15\", sep='\\t')\n",
    "test3 = pd.read_csv(\"./Lubos_data/dataset/channel_14\", sep='\\t')\n",
    "test4 = pd.read_csv(\"./Lubos_data/dataset/channel_13\", sep='\\t')\n",
    "test5 = pd.read_csv(\"./Lubos_data/dataset/channel_12\", sep='\\t')\n",
    "test6 = pd.read_csv(\"./Lubos_data/dataset/channel_11\", sep='\\t')\n",
    "test7 = pd.read_csv(\"./Lubos_data/dataset/channel_10\", sep='\\t')\n",
    "test8 = pd.read_csv(\"./Lubos_data/dataset/channel_9\", sep='\\t')\n",
    "\n",
    "\n",
    "x_test = np.concatenate([\n",
    "    np.asarray(test1['emg16']),\n",
    "    np.asarray(test2['emg15']), \n",
    "    np.asarray(test3['emg14']),\n",
    "    np.asarray(test4['emg13']),\n",
    "    np.asarray(test5['emg12']),\n",
    "    np.asarray(test6['emg11']),\n",
    "    np.asarray(test7['emg10']),\n",
    "    np.asarray(test8['emg9']),\n",
    "]).reshape(-1, size)\n",
    "\n",
    "y_test = np.concatenate([\n",
    "    np.asarray(test1['class']),\n",
    "    np.asarray(test2['class']), \n",
    "    np.asarray(test3['class']),\n",
    "    np.asarray(test4['class']),\n",
    "    np.asarray(test5['class']),\n",
    "    np.asarray(test6['class']),\n",
    "    np.asarray(test7['class']),\n",
    "    np.asarray(test8['class']),\n",
    "]).reshape(-1, size)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "22f96229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our model's structure\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(size,1)))\n",
    "model.add(Dropout(0.18))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.15))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c08cc",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4b1e9324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6907 - accuracy: 0.3205\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6891 - accuracy: 0.7628\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6875 - accuracy: 0.8369\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6860 - accuracy: 0.8578\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6845 - accuracy: 0.8633\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6830 - accuracy: 0.8643\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6815 - accuracy: 0.8639\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6801 - accuracy: 0.8626\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6786 - accuracy: 0.8616\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6772 - accuracy: 0.8607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d697820>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d093008",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "065de8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x13e432710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6761 - accuracy: 0.8689\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236ef49",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e9849",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2389b8",
   "metadata": {},
   "source": [
    "# Test the model on different subject (Jan channel 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e4f1080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612819, 4)\n"
     ]
    }
   ],
   "source": [
    "jan_test = pd.read_csv(\"./Jan_data/dataset/channel_1\", sep='\\t')\n",
    "\n",
    "print(jan_test.shape)\n",
    "\n",
    "x_jan_test = np.concatenate([\n",
    "    np.asarray(jan_test['emg1'])\n",
    "]).reshape(-1, 612819)\n",
    "\n",
    "y_jan_test = np.concatenate([\n",
    "    np.asarray(jan_test['class']),\n",
    "]).reshape(-1, 612819)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4e843683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 654ms/step - loss: 0.6816 - accuracy: 0.7613\n"
     ]
    }
   ],
   "source": [
    "jan_score = model.evaluate(x_jan_test, y_jan_test, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
